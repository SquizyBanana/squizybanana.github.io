"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[274],{1379:(e,t,o)=>{o.d(t,{A:()=>s});const s=o.p+"assets/images/SRDMindmap-fe09cf02a46d7057ee0faf0885c745f1.svg"},5387:(e,t,o)=>{o.d(t,{A:()=>s});const s=o.p+"assets/images/envisioninadition-c680c3405a943f1f9c470ecb47a4a943.jpg"},6243:(e,t,o)=>{o.d(t,{A:()=>s});const s=o.p+"assets/images/boardgame-cc5d00aeb2dc044b75dea26767548fc8.jpg"},7849:(e,t,o)=>{o.d(t,{A:()=>s});const s=o.p+"assets/images/actingweek3cards-5b272a05036fd6e9ad9126ced35855c5.jpg"},8453:(e,t,o)=>{o.d(t,{R:()=>a,x:()=>r});var s=o(6540);const i={},n=s.createContext(i);function a(e){const t=s.useContext(n);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(n.Provider,{value:t},e.children)}},8849:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>w,contentTitle:()=>b,default:()=>y,frontMatter:()=>f,metadata:()=>s,toc:()=>x});const s=JSON.parse('{"id":"Social Robot Design/GroupWork","title":"Group Work","description":"Week 1","source":"@site/docs/Social Robot Design/GroupWork.md","sourceDirName":"Social Robot Design","slug":"/Social Robot Design/GroupWork","permalink":"/docs/Social Robot Design/GroupWork","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Group Work"},"sidebar":"tutorialSidebar","previous":{"title":"Session 5","permalink":"/docs/Mastering Tinkering/Reflection questions/Week_5"},"next":{"title":"Session 1","permalink":"/docs/Social Robot Design/Reflective Questions/Session1"}}');var i=o(4848),n=o(8453);const a=o.p+"assets/images/paper1-c2b1ac919f1097cf79c06cc00e4576de.jpg",r=o.p+"assets/images/paper2-cb6e9157c070cf75cd48729b6d1ea0cb.jpg",h=o.p+"assets/images/paper3-d8e1284eb61e5c861e1abee5165577e8.jpg",d=o.p+"assets/images/paper4-4adc090f8bce942707ac059b5ae70b7b.jpg",l=o.p+"assets/images/paper5-21fde647f54932b6802e33b1aecf7a31.jpg",c=o.p+"assets/images/6-fd836eac42c76d52f12f30dc08ae6d97.png",p=o.p+"assets/images/20-c7fea96ac10eeeacf8ff4db2963ab2ca.png",u=o.p+"assets/images/32-eae1a6ad3047a2da0c59810c65202b60.png",m=o.p+"assets/images/Envision-a389f27396eea5d81dd6916faf08cb70.jpg",g=o.p+"assets/images/Envision2-eb55c916e5ed37161482cb941ddf6aea.jpg",f={title:"Group Work"},b=void 0,w={},x=[{value:"Week 1",id:"week-1",level:3},{value:"Week 2",id:"week-2",level:3},{value:"Week 3",id:"week-3",level:3},{value:"Week 4",id:"week-4",level:3},{value:"Week 5",id:"week-5",level:3},{value:"Week 6",id:"week-6",level:3},{value:"Week 7",id:"week-7",level:3}];function j(e){const t={a:"a",blockquote:"blockquote",code:"code",h3:"h3",img:"img",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,n.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h3,{id:"week-1",children:"Week 1"}),"\n",(0,i.jsx)(t.p,{children:"For the case we came up with a few posibilities such as performing automated non-invasive measurements, wayfinding, cleaning or other small household tasks and fetching things. There were also simpler cases like those shown in the example video but these seemed less interesting."}),"\n",(0,i.jsx)(t.p,{children:"From this we decided to continue with fecting, for which we determined it should be able to properly communicate with the people around it, hand things over without issue, avoid bumping into people while traveling and its movements should be smooth and predictable."}),"\n",(0,i.jsx)(t.p,{children:"As for the problem space, most of them relate to the actions to be performed by the robot. Especially during movement there are a lot of problems that could be encountered. Similarly in the building blocks most focus on the physical capabilities of the robot. Because of this most connections are also pretty straight forwards. The full mindmap can be seen below but might need some zooming in to see everything."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"My block",src:o(1379).A+"",width:"2280",height:"2227"})}),"\n",(0,i.jsx)(t.p,{children:'By adding remote controll elements to the robot, basically all of the comprehension and planning algorythims behind the driving and grabbing could in theory be "wizzard-of-ozzed". Our entire scenario of requesting the robot to fetch an item could also be translated to a theatrical exersize.'}),"\n",(0,i.jsx)(t.h3,{id:"week-2",children:"Week 2"}),"\n",(0,i.jsx)(t.p,{children:"Unfortunately I couldn't be at this lecture due to an overlap in my schedule so how the initial list of tools and ideas came to be I didn't experience. However, later that week we had a meeting to properly work out the tool and scenario. Here, we started from the two categorisations often used to describe how people write their first drafts in literature: Botanist writing and Gardener writing. Botanist writing is much more about letting the story grow naturally while observing what it does, where as Gardener writing is much more focused on planning, structure and predifined goals. We came up with exersizes for both. From these, the Gardener exsersizes fit better into Social Robot Design. Our final selected exersize/tool looks as follows:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"- One person defines the goal (instructor)\r\n- (Optional) Define limitations (e.g. can only use 1 hand, no hands, close your eyes, etc)\r\n- (Optional) Include use of tools, e.g. grippers, containers, wheelchairs, etc.\r\n- (Optional) Include environmental factors if these are of importance.\r\n- It is better if the 2nd person (actor) does not know the goal\r\n- The instructor asks the actor to perform a certain short instruction\r\n- The actor performs this action as literally as possible\r\n- Record (in writing or video recording) how the action is performed\r\n- Try to come up with better ways to define/perform actions/instructions?\r\n- Repeat until the instructions are able to complete the goal.\n"})}),"\n",(0,i.jsxs)(t.p,{children:["This exersize is strongly based on ",(0,i.jsx)(t.a,{href:"https://www.youtube.com/watch?v=j-6N3bLgYyQ",children:"this exersize"})," parents or teachers sometimes do with children. While this isn't exactly an academic grounding, it does clearly show how quickly a method like this can discover issues with the instructions provided. It also gives a good indication of how granular the process design should be made. Furthermore this method also has some of the same benefits as bodystorming, as it encourages the participants to use their body to experiance the envisioned actions. One of the possible scenarios that could be analised with this tool goes as follows:"]}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsx)(t.p,{children:"Someone has fallen and the nurse is there to help, but does not have all they need to properly provide aid. The fallen person is still calling for help too. The nurse asks the robot to go fetch the last things they need."}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"This scenario poses questions such as:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"- Does the robot follow the nurse's instructions or help the person calling for help?\r\n- Can the robot find what was asked of them?\r\n- Can the robot avoid running into and/or toppling over other people on its way?\r\n- Does it know how many drugs it needs to fetch?\r\n- What is the overall order of actions that the robot will do in case of an emergency?\n"})}),"\n",(0,i.jsx)(t.h3,{id:"week-3",children:"Week 3"}),"\n",(0,i.jsx)(t.p,{children:"For week 3 the task was to design a tool to develop expressive behaviour for a social robot. For this we first listed a bunch of possible motions, sounds, light effects, morphologies, haptics and controll schemes that could be used to display emotions. However, with this we didn't get very far. Similarly, trying to categorize traits by their emotions didn't really lead to a suitable tool. For this papers like Terwogt and Hoeksma [1] were used. After this, we looked into limiting ourselves strictly to sounds, where the user had to express different sounds through only a synthesizer. Then there would be cards of different scenario's which you had to act out. While we had a hard time figuring out how to make the sythesizer idea work, we liked the cards idea so our final result was somewhat similar to the previous week in that the tool mainly revolves around acting out scenario's. Just more focused on expression and communication then the scenario itself like last week."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"My block",src:o(7849).A+"",width:"908",height:"2016"})}),"\n",(0,i.jsx)(t.p,{children:"This tool contains three sets of cards. Location, Goal and Modifier cards. These cards set the scenario for the bodystorm session. The participants can either select cards that fit their already existing scenario, or if they do not have a scenario they can pick at least one card from each type at random. It's not reccomeneded to pick multiple location cards at the same time. Once the actor playing the robot knows their goal, they must put on a mask. This is to prevent the facial expressions of us humans to influence the session. Unfortunately, it isn't always possible for people to hide their facial expressions [2], especially if this tool is to be used by designers who will most likely not have proffesional acting training. Once everyone knows what they are doing, the acting begins. During this, the actor playing the robot tries to as effectively as possible complete its goal, while at least one notetaker writes down interesting observations about the behaviour of the robot actor and how the human actors react to them. It is also reccomened to make a video recording of the exercise for later analySsis."}),"\n",(0,i.jsx)(t.p,{children:"The main advantage we found during testing of this tool is that as the robot actor, you experiance first hand what modalities you need in order to complete your task. Furthermore it also can put your robot in slightly more unusual scenario's and allows you to explore how the robot needs to both express itself and behave in general to complete it's task."}),"\n",(0,i.jsx)(t.p,{children:'[1] Terwogt, M. M., & Hoeksma, J. B. (1995). "Colors and Emotions: Preferences and Combinations." The Journal of General Psychology, 122(1), 5\u201317. doi:10.1080/00221309.1995.9921217\xa0'}),"\n",(0,i.jsx)(t.p,{children:'[2] Kappas, A., Bherer, F., & Th\xe9riault, M. (2000). "Inhibiting Facial Expressions: Limitations to the\r\nVoluntary Control of Facial Expressions of Emotion." Motivation and Emotion, 24(4), 259\u2013270. doi:10.1023/a:1010718815960\xa0'}),"\n",(0,i.jsx)(t.h3,{id:"week-4",children:"Week 4"}),"\n",(0,i.jsx)(t.p,{children:'Taking a quick look at some more recent papers, pepper and Nao are still used quite a lot. Not as much as a few years ago, but they are defenetly still the "market lead" as it were. The morphological overview wasn\'t as clear to us, whether or not we were supposed to put existing robots in this or the possible funcitons of the robot. We decided to go with the latter.'}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"Morphological"}),(0,i.jsx)(t.th,{children:"overview"}),(0,i.jsx)(t.th,{}),(0,i.jsx)(t.th,{}),(0,i.jsx)(t.th,{}),(0,i.jsx)(t.th,{}),(0,i.jsx)(t.th,{})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Morphology"}),(0,i.jsx)(t.td,{children:"Human like"}),(0,i.jsx)(t.td,{children:"Simple shapes"}),(0,i.jsx)(t.td,{children:"Animal like"}),(0,i.jsx)(t.td,{children:"Traditional robot design"}),(0,i.jsx)(t.td,{children:"Custom design"}),(0,i.jsx)(t.td,{})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"face"}),(0,i.jsx)(t.td,{children:"Screen"}),(0,i.jsx)(t.td,{children:"Morphological eyes"}),(0,i.jsx)(t.td,{children:"Motorized facial features"}),(0,i.jsx)(t.td,{children:"none"}),(0,i.jsx)(t.td,{}),(0,i.jsx)(t.td,{})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"color"}),(0,i.jsx)(t.td,{children:"white"}),(0,i.jsx)(t.td,{children:"accents"}),(0,i.jsx)(t.td,{children:"\u201cnatural\u201d"}),(0,i.jsx)(t.td,{children:"party"}),(0,i.jsx)(t.td,{}),(0,i.jsx)(t.td,{})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"motion"}),(0,i.jsx)(t.td,{children:"static"}),(0,i.jsx)(t.td,{children:"fluid"}),(0,i.jsx)(t.td,{children:"breathing"}),(0,i.jsx)(t.td,{children:"jitters"}),(0,i.jsx)(t.td,{children:"animated"}),(0,i.jsx)(t.td,{})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"voice"}),(0,i.jsx)(t.td,{children:"noises"}),(0,i.jsx)(t.td,{children:"flat"}),(0,i.jsx)(t.td,{children:"expressive"}),(0,i.jsx)(t.td,{children:"none"}),(0,i.jsx)(t.td,{}),(0,i.jsx)(t.td,{})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"size"}),(0,i.jsx)(t.td,{children:"Toy size"}),(0,i.jsx)(t.td,{children:"Desktop size"}),(0,i.jsx)(t.td,{children:"Child size"}),(0,i.jsx)(t.td,{children:"Human size"}),(0,i.jsx)(t.td,{children:"Even larger"}),(0,i.jsx)(t.td,{})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"locomotion"}),(0,i.jsx)(t.td,{children:"legs"}),(0,i.jsx)(t.td,{children:"wheels"}),(0,i.jsx)(t.td,{children:"threads"}),(0,i.jsx)(t.td,{children:"none"}),(0,i.jsx)(t.td,{}),(0,i.jsx)(t.td,{})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"location"}),(0,i.jsx)(t.td,{children:"classroom"}),(0,i.jsx)(t.td,{children:"library"}),(0,i.jsx)(t.td,{children:"home"}),(0,i.jsx)(t.td,{children:"office"}),(0,i.jsx)(t.td,{children:"restaurant"}),(0,i.jsx)(t.td,{children:"etc."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"users"}),(0,i.jsx)(t.td,{children:"teachers"}),(0,i.jsx)(t.td,{children:"librarians"}),(0,i.jsx)(t.td,{children:"homeowner"}),(0,i.jsx)(t.td,{children:"employees"}),(0,i.jsx)(t.td,{children:"guests"}),(0,i.jsx)(t.td,{children:"etc."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"goal"}),(0,i.jsx)(t.td,{children:"education"}),(0,i.jsx)(t.td,{children:"organisation"}),(0,i.jsx)(t.td,{children:"cleaning"}),(0,i.jsx)(t.td,{children:"Emotional support"}),(0,i.jsx)(t.td,{children:"serving"}),(0,i.jsx)(t.td,{children:"etc."})]})]})]}),"\n",(0,i.jsx)(t.p,{children:"As these features were picked to fit social robots, there isn't a single feature that doesn't fit a social robot. However, you can defenetly create scenario's that make no sense with this overview, like an education robot that can only communicate through beeps or a static cleaning robot."}),"\n",(0,i.jsx)(t.p,{children:"For the tool of this week we started with the idea of a \"mr potato\" design kit, where you had certain shapes and functions of the robot that you could freely attach over the whole body. But while looking for academic support we found the paper by Voges et al. [3] where they use paper instead. This allows for the extra benefit that the designer can draw in featueres that weren't available in the kit itself. Voges et al. used a lot of predefined shapes however, as they were more interested in the layperson's assumptions, theories and ideas about social robots then to design new ones. That is why for our kit we decided to go with very simple shapes like squares, rechtangles, circles and triangles of varing sizes."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"building paper",src:o(8996).A+"",width:"1816",height:"4032"})}),"\n",(0,i.jsx)(t.p,{children:"The fact that the shapes were so simple seemed to lead to a lot of different designs even within our own group during the testing. And indeed once the general shape was down its nice to be able to quickly grab a pen or marker and draw on some features to further elaborate on your design."}),"\n",(0,i.jsx)("img",{src:a,style:{width:150}}),"\n",(0,i.jsx)("img",{src:r,style:{width:150}}),"\n",(0,i.jsx)("img",{src:h,style:{width:150}}),"\n",(0,i.jsx)("img",{src:d,style:{width:150}}),"\n",(0,i.jsx)("img",{src:l,style:{width:150}}),"\n",(0,i.jsx)(t.p,{children:'[3] A. Voges, M. E. Foster, & E. S. Cross, (2024) "Human, Animal, or Machine? A Design-Based Exploration of Social\r\nRobot Embodiment with a Creative Toolkit*" 33rd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)\r\nAugust 26-30, 2024, DOI: 10.1109/RO-MAN60168.2024.10731416'}),"\n",(0,i.jsx)(t.h3,{id:"week-5",children:"Week 5"}),"\n",(0,i.jsxs)(t.p,{children:["The main developments on Rose and Rose 2.0 are centered around the automation of checking in on patients (the \u201ctaking a look through the door to see if they are ok\u201d kind, not the medical kind) and the collection, fetching and transport of small objects such as medicine, towels or remotes[4][5]. This last note indicates that the strength in ROSE\u2019s arm is not strong at all. There aren\u2019t a lot of expressive modalities mentioned on either the HIT or ROSE website, but in the ",(0,i.jsx)(t.a,{href:"https://www.youtube.com/watch?v=cA8mtkqo-zw&t=7s",children:"video of the robot"})," it seems to be able to use its head, arm and torso movements to create some limited body language. Its face cannot be changed, as it is shaped into the plastic around the head with the cameras. HIT themselves claim that they were involved since the start of the development of their SACRo program, but its unclear whether or not PAL had already developed the Tiago base before. PAL offers the tiago in many variants by now, but it seems that for ROSE, HIT chose to use the differential base and a single arm with the parallel gripper including torque sensor. HIT added a screen above the head to the physical setup, with most likely a lot of software to support their SACRo program. The robot in this configuration has a clear head with the camera\u2019s being in the eyes and a smiling mouth in the external housing. Furthermore, given the number of joints in the arm, as long as its extended forwards it reasonably looks like a human arm. Overall the rest of the robot looks a lot like a coffee machine however. This is more likely required by the intended functionality than an aesthetics consideration."]}),"\n",(0,i.jsxs)(t.p,{children:["[4] ",(0,i.jsx)(t.a,{href:"https://heemskerk-innovative.nl/projects/overview/health",children:"https://heemskerk-innovative.nl/projects/overview/health"})]}),"\n",(0,i.jsxs)(t.p,{children:["[5] ",(0,i.jsx)(t.a,{href:"https://robot-rose.com/",children:"https://robot-rose.com/"})]}),"\n",(0,i.jsx)(t.h3,{id:"week-6",children:"Week 6"}),"\n",(0,i.jsx)(t.p,{children:"This is the big one. For the behavioural design assignment we decided to create a boardgame."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"building paper",src:o(6243).A+"",width:"2016",height:"908"})}),"\n",(0,i.jsx)(t.p,{children:"This game is set in an elderly care home where every player plays one care robot. The game features a plethora of goal cards that the players have to acchieve in order to score points. In order to complete these cards however the player needs to convince their competitors that their robot has the necesairy capabilities to do so. These capabilities are defined by what robot parts have been equipped. The core of what constitures to the behavioural design lies in this explaning how and with what tools your robot manages to complete the assigned task. During the development, more story like games like Degrees of Freedom by Mott et al. [6] were also considered but this was considered to be too \"open\", where there was so little steering that the more unexpected scenario's wouldn't really get covered. To induce more of these unexpected scenario's, as well as to improve overall gameplay fun, action cards were also added. Further gameification things include moving the elderly, charging your robot and completing the final goal first. The robot cards also have energy and computation costs. Energy is paid per turn depending on what card is used, and can be recharged at the charging station. Computation points add up to a maximum."}),"\n",(0,i.jsx)("img",{src:c,style:{width:250}}),"\n",(0,i.jsx)("img",{src:p,style:{width:250}}),"\n",(0,i.jsx)("img",{src:u,style:{width:250}}),"\n",(0,i.jsx)(t.p,{children:'[6] T. Mott, M. Higger, A. Bejarano and T. Williams, (2024) "Degrees of Freedom: A Storytelling Game that Supports Technology Literacy about Social Robots," 2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN), Pasadena, CA, USA, pp. 2095-2102, doi: 10.1109/RO-MAN60168.2024.10731340.'}),"\n",(0,i.jsx)(t.h3,{id:"week-7",children:"Week 7"}),"\n",(0,i.jsx)(t.p,{children:"Given how much work the game was to make, we decided to keep it much simpler for the last week. We decided to simply expand the envisioning cards [7] with cards more suitable towards social robot design. Topics included things like cloud reliability, supply of replacement parts, changing societal values, intuative use and bias. Each card has a little introduction to the topic, as well as an excersize that should help think about the topic listed on the cards."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"building paper",src:o(5387).A+"",width:"908",height:"2016"})}),"\n",(0,i.jsx)("img",{src:m,style:{width:350}}),"\n",(0,i.jsx)("img",{src:g,style:{width:350}}),"\n",(0,i.jsxs)(t.p,{children:["[7] Batya Friedman, Lisa Nathan, Shaun Kane, John Lin, Daisy Yoo, Nick Logler, Stephanie Ballard, and David G. Hendry. Envisioning Cards: A Value Sensitive Design Toolkit (2nd Edition). Seattle, WA: University of Washington, 2024. ",(0,i.jsx)(t.a,{href:"https://envisioningcards.vsdesign.org",children:"https://envisioningcards.vsdesign.org"})]})]})}function y(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(j,{...e})}):j(e)}},8996:(e,t,o)=>{o.d(t,{A:()=>s});const s=o.p+"assets/images/buildingpieces-5b0b9c19121ed7a5e5323893f630d46c.jpg"}}]);